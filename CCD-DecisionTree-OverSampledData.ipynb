{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier as DT_SK\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# from mlxtend.plotting import plot_learning_curves\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Built Decision Tree Class\n",
    "\n",
    "A decision tree is a type of machine learning algorithm that is used for both classification and regression tasks. It is a tree-like model where internal nodes represent a decision based on the values of one or more input features, and branches represent the possible outcomes of that decision. The leaves of the tree represent the final output or classification. We built a custom class called _DecisionTreeClassifier_ to train and predict values for the data set that we have. We defined a constructor  that takes two optional parameters: max_depth and min_samples_split. The max_depth parameter controls the maximum depth of the decision tree, while the min_samples_split parameter controls the minimum number of samples required to split an internal node.\n",
    "\n",
    "The _fit()_ function takes the training data X and its corresponding labels y, and trains the model by recursively building the decision tree using the _ _build_tree()_ _ function.\n",
    "\n",
    "The _ _predict()_ _ function takes an input array X and returns an array of predictions based on the trained decision tree model.\n",
    "\n",
    "The _ _build_tree()_ _ function is the heart of the algorithm and builds the decision tree recursively. It starts by checking if the stopping criterion has been met, which is defined as any of the following conditions: the depth of the tree has reached the maximum allowed, there is only one class label left in the data, or the number of samples is less than the minimum required to split an internal node. If any of these conditions are true, the method returns a leaf node with the most frequent class label.\n",
    "\n",
    "Otherwise, it selects the best feature and threshold to split the data using the _ _best_split()_ _ function. It then splits the data into two subsets based on the selected feature and threshold, and recursively builds the decision tree for each subset. Finally, it returns an internal node representing the selected feature and threshold, as well as the two subtrees.\n",
    "\n",
    "The _ _best_split()_ _ function calculates the information gain for each feature and threshold combination and returns the feature and threshold with the highest information gain.\n",
    "\n",
    "The _ _gini_impurity()_ _ function calculates the impurity of the data split based on the Gini impurity criterion.\n",
    "\n",
    "The _ _decision_node()_ _ function creates an internal node representing a decision based on the selected feature and threshold, as well as the two subtrees.\n",
    "\n",
    "The _ _leaf_node()_ _ function creates a leaf node representing the most frequent class label in the data subset.\n",
    "\n",
    "The _ _predict_one()_ _ function takes an input array x and traverses the decision tree model until it reaches a leaf node, which represents the predicted class label for x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        print(f\"Fitting the Decision Tree Classifier with {len(np.unique(y))} classes...\")\n",
    "        self.tree_ = self._build_tree(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        predictions = []\n",
    "        for i in range(X.shape[0]):\n",
    "            predictions.append(self._predict_one(X[i]))\n",
    "        return np.array(predictions)\n",
    "        \n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        num_samples, num_features = X.shape\n",
    "        \n",
    "        if (depth >= self.max_depth or len(np.unique(y)) == 1 or num_samples < self.min_samples_split):\n",
    "            return self._leaf_node(y)\n",
    "        \n",
    "        best_feature, best_threshold = self._best_split(X, y, num_samples, num_features)\n",
    "        \n",
    "        left_indices = X[:, best_feature] < best_threshold\n",
    "        right_indices = X[:, best_feature] >= best_threshold\n",
    "        \n",
    "        if (len(X[left_indices]) == 0 or len(X[right_indices]) == 0):\n",
    "            return self._leaf_node(y)\n",
    "        \n",
    "        print(\"Depth:\", depth)\n",
    "        print(\"Samples:\", num_samples)\n",
    "        print(\"Features:\", num_features)\n",
    "        print(\"Best feature:\", best_feature)\n",
    "        print(\"Best threshold:\", best_threshold)\n",
    "        print(\"Left samples:\", len(X[left_indices]))\n",
    "        print(\"Right samples:\", len(X[right_indices]))\n",
    "        print(\"=\"*30)\n",
    "        \n",
    "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth+1)\n",
    "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth+1)\n",
    "        \n",
    "        \n",
    "        return self._decision_node(best_feature, best_threshold, left_tree, right_tree)\n",
    "\n",
    "        \n",
    "    def _best_split(self, X, y, num_samples, num_features):\n",
    "        print(\"Calculating information gain for each feature...\")\n",
    "        best_impurity = float('inf')\n",
    "        best_feature, best_threshold = None, None\n",
    "        \n",
    "        for feature in range(num_features):\n",
    "            print(f\"Feature {feature}\")\n",
    "            feature_values = np.expand_dims(X[:, feature], axis=1)\n",
    "            unique_values = np.unique(feature_values)\n",
    "            \n",
    "            for threshold in unique_values:\n",
    "                left_indices = X[:, feature] < threshold\n",
    "                right_indices = X[:, feature] >= threshold\n",
    "                \n",
    "                if (np.sum(left_indices) == 0 or np.sum(right_indices) == 0):\n",
    "                    continue\n",
    "                \n",
    "                left_labels = y[left_indices]\n",
    "                right_labels = y[right_indices]\n",
    "                \n",
    "                impurity = self._gini_impurity(left_labels, right_labels, num_samples)\n",
    "                \n",
    "                if (impurity < best_impurity):\n",
    "                    best_impurity = impurity\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "                    \n",
    "        return best_feature, best_threshold\n",
    "    \n",
    "    def _gini_impurity(self, left_labels, right_labels, num_samples):\n",
    "        p_l = len(left_labels) / num_samples\n",
    "        p_r = len(right_labels) / num_samples\n",
    "        \n",
    "        gini_l = 1.0 - np.sum(np.power(np.unique(left_labels, return_counts=True)[1]/len(left_labels), 2))\n",
    "        gini_r = 1.0 - np.sum(np.power(np.unique(right_labels, return_counts=True)[1]/len(right_labels), 2))\n",
    "        \n",
    "        impurity = (p_l * gini_l) + (p_r * gini_r)\n",
    "        return impurity\n",
    "        \n",
    "    def _decision_node(self, feature, threshold, left_tree, right_tree):\n",
    "        return {'feature': feature, 'threshold': threshold, 'left': left_tree, 'right': right_tree}\n",
    "        \n",
    "    def _leaf_node(self, y):\n",
    "        return np.bincount(y).argmax()\n",
    "    \n",
    "    def _predict_one(self, x):\n",
    "        node = self.tree_\n",
    "        while isinstance(node, dict):\n",
    "            if x[node['feature']] < node['threshold']:\n",
    "                node = node['left']\n",
    "            else:\n",
    "                node = node['right']\n",
    "        if isinstance(node, np.int64):\n",
    "            return node\n",
    "        else:\n",
    "            print(f\"Unexpected node type {type(node)} with value {node}\")\n",
    "            raise ValueError(f\"Unexpected node type {type(node)} in prediction\")\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding and Data Preparation\n",
    "The Dataset we use is the Kaggle Credit Card Fraud Detection Dataset enlisted in the following link: <a href=\"https://www.kaggle.com/mlg-ulb/creditcardfraud\">Link</a>\n",
    "Since the data set is imbalanced SMOTE technique is used ti balance the datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data into a Dataframe\n",
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.165980e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.373150e-15</td>\n",
       "      <td>2.086869e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.490107e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.177556e-16</td>\n",
       "      <td>-2.406455e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.656562e-16</td>\n",
       "      <td>-3.444850e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.471968e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.687098e-15</td>\n",
       "      <td>-3.666453e-16</td>\n",
       "      <td>-1.220404e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.165980e-15  3.416908e-16 -1.373150e-15  2.086869e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.490107e-15 -5.556467e-16  1.177556e-16 -2.406455e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.656562e-16 -3.444850e-16  2.578648e-16  4.471968e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.687098e-15 -3.666453e-16 -1.220404e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe Data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train and Test Data in ratio 70:30\n",
    "X = df.drop(labels='Class', axis=1) # Features\n",
    "y = df.loc[:,'Class']               # Target Variable\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  4  7 10 11 12 14 16 17 18]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create the feature selector\n",
    "selector = SelectKBest(score_func=f_classif, k=10)\n",
    "\n",
    "# fit the selector to the training data\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# transform the data to include only the selected features\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "X_train_selected_df = pd.DataFrame(X_train_selected, columns=X_train.columns[selector.get_support()])\n",
    "X_test_selected_df = pd.DataFrame(X_test_selected, columns=X_test.columns[selector.get_support()])\n",
    "\n",
    "\n",
    "\n",
    "# print the indices of the selected features\n",
    "print(selector.get_support(indices=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199364, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Synthetic Minority Oversampling\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train_selected_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398040, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing feature selection to reduce dimensionality\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "mutual_infos = pd.Series(data=mutual_info_classif(X_res, y_res, discrete_features=False, random_state=1), index=X_train_selected_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V14    0.483617\n",
       "V17    0.446763\n",
       "V10    0.421289\n",
       "V12    0.410546\n",
       "V4     0.399749\n",
       "V11    0.368977\n",
       "V3     0.345968\n",
       "V16    0.335298\n",
       "V7     0.288954\n",
       "V18    0.202024\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_infos.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute class distribution in y_res\n",
    "class_counts = y_res.value_counts()\n",
    "\n",
    "# Plot pie chart of class distribution\n",
    "plt.pie(class_counts, labels=class_counts.index, autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.title('Using Synthetic Minority Oversampling on Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V7</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V14</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.703924</td>\n",
       "      <td>0.069871</td>\n",
       "      <td>-0.897198</td>\n",
       "      <td>0.396879</td>\n",
       "      <td>0.268544</td>\n",
       "      <td>0.752264</td>\n",
       "      <td>-0.252977</td>\n",
       "      <td>-3.211514</td>\n",
       "      <td>1.648897</td>\n",
       "      <td>-1.297012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.347969</td>\n",
       "      <td>-0.379954</td>\n",
       "      <td>0.081125</td>\n",
       "      <td>-1.275754</td>\n",
       "      <td>-1.871478</td>\n",
       "      <td>0.375166</td>\n",
       "      <td>-0.149358</td>\n",
       "      <td>0.802805</td>\n",
       "      <td>-0.405073</td>\n",
       "      <td>0.153925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.615556</td>\n",
       "      <td>2.362138</td>\n",
       "      <td>0.574245</td>\n",
       "      <td>2.035115</td>\n",
       "      <td>-0.564418</td>\n",
       "      <td>-1.407557</td>\n",
       "      <td>-0.859411</td>\n",
       "      <td>0.099132</td>\n",
       "      <td>-0.035668</td>\n",
       "      <td>-0.053624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.755202</td>\n",
       "      <td>-0.963160</td>\n",
       "      <td>-0.794616</td>\n",
       "      <td>-0.939787</td>\n",
       "      <td>1.101727</td>\n",
       "      <td>1.138109</td>\n",
       "      <td>0.156943</td>\n",
       "      <td>-0.419096</td>\n",
       "      <td>-0.207755</td>\n",
       "      <td>0.403235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.784402</td>\n",
       "      <td>1.254973</td>\n",
       "      <td>-0.161727</td>\n",
       "      <td>0.015787</td>\n",
       "      <td>1.084154</td>\n",
       "      <td>1.016011</td>\n",
       "      <td>0.250706</td>\n",
       "      <td>-0.130522</td>\n",
       "      <td>-0.216624</td>\n",
       "      <td>-0.058071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398035</th>\n",
       "      <td>-6.522159</td>\n",
       "      <td>6.281158</td>\n",
       "      <td>-1.813694</td>\n",
       "      <td>-6.105619</td>\n",
       "      <td>6.670137</td>\n",
       "      <td>-8.784105</td>\n",
       "      <td>-10.763121</td>\n",
       "      <td>-1.644586</td>\n",
       "      <td>-1.741353</td>\n",
       "      <td>0.735553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398036</th>\n",
       "      <td>-1.195963</td>\n",
       "      <td>3.986840</td>\n",
       "      <td>-0.335601</td>\n",
       "      <td>0.367141</td>\n",
       "      <td>0.552932</td>\n",
       "      <td>-0.025719</td>\n",
       "      <td>-2.903445</td>\n",
       "      <td>2.385874</td>\n",
       "      <td>0.720317</td>\n",
       "      <td>1.786077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398037</th>\n",
       "      <td>-19.005693</td>\n",
       "      <td>10.827232</td>\n",
       "      <td>-15.180158</td>\n",
       "      <td>-13.172716</td>\n",
       "      <td>6.855373</td>\n",
       "      <td>-15.285840</td>\n",
       "      <td>-11.726785</td>\n",
       "      <td>-9.538214</td>\n",
       "      <td>-17.222798</td>\n",
       "      <td>-6.895070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398038</th>\n",
       "      <td>-3.437895</td>\n",
       "      <td>4.078456</td>\n",
       "      <td>0.896141</td>\n",
       "      <td>-2.405003</td>\n",
       "      <td>1.846422</td>\n",
       "      <td>-2.070625</td>\n",
       "      <td>-6.996105</td>\n",
       "      <td>2.237485</td>\n",
       "      <td>6.483626</td>\n",
       "      <td>1.818848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398039</th>\n",
       "      <td>-19.866900</td>\n",
       "      <td>6.635924</td>\n",
       "      <td>-21.266283</td>\n",
       "      <td>-17.984234</td>\n",
       "      <td>4.988514</td>\n",
       "      <td>-10.598704</td>\n",
       "      <td>-8.233999</td>\n",
       "      <td>-8.838695</td>\n",
       "      <td>-18.176982</td>\n",
       "      <td>-7.460210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398040 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V3         V4         V7        V10       V11        V12  \\\n",
       "0        0.703924   0.069871  -0.897198   0.396879  0.268544   0.752264   \n",
       "1        1.347969  -0.379954   0.081125  -1.275754 -1.871478   0.375166   \n",
       "2        2.615556   2.362138   0.574245   2.035115 -0.564418  -1.407557   \n",
       "3        0.755202  -0.963160  -0.794616  -0.939787  1.101727   1.138109   \n",
       "4        0.784402   1.254973  -0.161727   0.015787  1.084154   1.016011   \n",
       "...           ...        ...        ...        ...       ...        ...   \n",
       "398035  -6.522159   6.281158  -1.813694  -6.105619  6.670137  -8.784105   \n",
       "398036  -1.195963   3.986840  -0.335601   0.367141  0.552932  -0.025719   \n",
       "398037 -19.005693  10.827232 -15.180158 -13.172716  6.855373 -15.285840   \n",
       "398038  -3.437895   4.078456   0.896141  -2.405003  1.846422  -2.070625   \n",
       "398039 -19.866900   6.635924 -21.266283 -17.984234  4.988514 -10.598704   \n",
       "\n",
       "              V14       V16        V17       V18  \n",
       "0       -0.252977 -3.211514   1.648897 -1.297012  \n",
       "1       -0.149358  0.802805  -0.405073  0.153925  \n",
       "2       -0.859411  0.099132  -0.035668 -0.053624  \n",
       "3        0.156943 -0.419096  -0.207755  0.403235  \n",
       "4        0.250706 -0.130522  -0.216624 -0.058071  \n",
       "...           ...       ...        ...       ...  \n",
       "398035 -10.763121 -1.644586  -1.741353  0.735553  \n",
       "398036  -2.903445  2.385874   0.720317  1.786077  \n",
       "398037 -11.726785 -9.538214 -17.222798 -6.895070  \n",
       "398038  -6.996105  2.237485   6.483626  1.818848  \n",
       "398039  -8.233999 -8.838695 -18.176982 -7.460210  \n",
       "\n",
       "[398040 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we can say that the most correlated features after resolving class imbalance using Synthetic Minority Oversampling are V14, V10, V4, V12 and V17."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We make use of AUC-ROC Score, Classification Report, Accuracy and F1-Score to evaluate the performance of the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of Classifiers\n",
    "def grid_eval(grid_clf):\n",
    "    \"\"\"\n",
    "        Method to Compute the best score and parameters computed by grid search\n",
    "        Parameter:\n",
    "            grid_clf: The Grid Search Classifier \n",
    "    \"\"\"\n",
    "    print(\"Best Score\", grid_clf.best_score_)\n",
    "    print(\"Best Parameter\", grid_clf.best_params_)\n",
    "    \n",
    "def evaluation(y_test, grid_clf, X_test):\n",
    "    \"\"\"\n",
    "        Method to compute the following:\n",
    "            1. Classification Report\n",
    "            2. F1-score\n",
    "            3. AUC-ROC score\n",
    "            4. Accuracy\n",
    "        Parameters:\n",
    "            y_test: The target variable test set\n",
    "            grid_clf: Grid classifier selected\n",
    "            X_test: Input Feature Test Set\n",
    "    \"\"\"\n",
    "    y_pred = grid_clf.predict(X_test)\n",
    "    print('CLASSIFICATION REPORT')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('AUC-ROC')\n",
    "    print(roc_auc_score(y_test, y_pred))\n",
    "      \n",
    "    print('F1-Score')\n",
    "    print(f1_score(y_test, y_pred))\n",
    "    \n",
    "    print('Accuracy')\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398040, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398040,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the Decision Tree Classifier with 2 classes...\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 0\n",
      "Samples: 398040\n",
      "Features: 10\n",
      "Best feature: 6\n",
      "Best threshold: -1.81320586496503\n",
      "Left samples: 178147\n",
      "Right samples: 219893\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 1\n",
      "Samples: 178147\n",
      "Features: 10\n",
      "Best feature: 1\n",
      "Best threshold: -0.49694592100899615\n",
      "Left samples: 1951\n",
      "Right samples: 176196\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 2\n",
      "Samples: 1951\n",
      "Features: 10\n",
      "Best feature: 3\n",
      "Best threshold: -4.00268278841043\n",
      "Left samples: 108\n",
      "Right samples: 1843\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 3\n",
      "Samples: 1843\n",
      "Features: 10\n",
      "Best feature: 6\n",
      "Best threshold: -1.8519519988741082\n",
      "Left samples: 1673\n",
      "Right samples: 170\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 4\n",
      "Samples: 170\n",
      "Features: 10\n",
      "Best feature: 4\n",
      "Best threshold: 1.1531462901693716\n",
      "Left samples: 93\n",
      "Right samples: 77\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 2\n",
      "Samples: 176196\n",
      "Features: 10\n",
      "Best feature: 3\n",
      "Best threshold: -1.72530146296239\n",
      "Left samples: 160758\n",
      "Right samples: 15438\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 3\n",
      "Samples: 160758\n",
      "Features: 10\n",
      "Best feature: 5\n",
      "Best threshold: 0.32269442775471996\n",
      "Left samples: 160707\n",
      "Right samples: 51\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 4\n",
      "Samples: 160707\n",
      "Features: 10\n",
      "Best feature: 4\n",
      "Best threshold: 0.18686265838645208\n",
      "Left samples: 916\n",
      "Right samples: 159791\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 4\n",
      "Samples: 51\n",
      "Features: 10\n",
      "Best feature: 1\n",
      "Best threshold: 2.089480507142379\n",
      "Left samples: 39\n",
      "Right samples: 12\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 3\n",
      "Samples: 15438\n",
      "Features: 10\n",
      "Best feature: 1\n",
      "Best threshold: 1.9852444715729392\n",
      "Left samples: 5454\n",
      "Right samples: 9984\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 4\n",
      "Samples: 5454\n",
      "Features: 10\n",
      "Best feature: 6\n",
      "Best threshold: -1.9485073597135834\n",
      "Left samples: 3800\n",
      "Right samples: 1654\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 4\n",
      "Samples: 9984\n",
      "Features: 10\n",
      "Best feature: 3\n",
      "Best threshold: 1.1170469744043703\n",
      "Left samples: 9860\n",
      "Right samples: 124\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 1\n",
      "Samples: 219893\n",
      "Features: 10\n",
      "Best feature: 1\n",
      "Best threshold: 1.4139979129515243\n",
      "Left samples: 185942\n",
      "Right samples: 33951\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 2\n",
      "Samples: 185942\n",
      "Features: 10\n",
      "Best feature: 6\n",
      "Best threshold: -0.663148423111059\n",
      "Left samples: 32621\n",
      "Right samples: 153321\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 3\n",
      "Samples: 32621\n",
      "Features: 10\n",
      "Best feature: 1\n",
      "Best threshold: -0.015963197212288227\n",
      "Left samples: 16417\n",
      "Right samples: 16204\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 4\n",
      "Samples: 16417\n",
      "Features: 10\n",
      "Best feature: 6\n",
      "Best threshold: -1.60370606146578\n",
      "Left samples: 1285\n",
      "Right samples: 15132\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 4\n",
      "Samples: 16204\n",
      "Features: 10\n",
      "Best feature: 5\n",
      "Best threshold: -0.09120392373897802\n",
      "Left samples: 7402\n",
      "Right samples: 8802\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 3\n",
      "Samples: 153321\n",
      "Features: 10\n",
      "Best feature: 2\n",
      "Best threshold: 1.0759740427341993\n",
      "Left samples: 138798\n",
      "Right samples: 14523\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 4\n",
      "Samples: 138798\n",
      "Features: 10\n",
      "Best feature: 6\n",
      "Best threshold: 0.0113405871729419\n",
      "Left samples: 53813\n",
      "Right samples: 84985\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 4\n",
      "Samples: 14523\n",
      "Features: 10\n",
      "Best feature: 1\n",
      "Best threshold: 0.159765343461169\n",
      "Left samples: 8970\n",
      "Right samples: 5553\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 2\n",
      "Samples: 33951\n",
      "Features: 10\n",
      "Best feature: 5\n",
      "Best threshold: -0.283695641477279\n",
      "Left samples: 17265\n",
      "Right samples: 16686\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 3\n",
      "Samples: 17265\n",
      "Features: 10\n",
      "Best feature: 0\n",
      "Best threshold: 1.26305700668815\n",
      "Left samples: 14321\n",
      "Right samples: 2944\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 4\n",
      "Samples: 14321\n",
      "Features: 10\n",
      "Best feature: 6\n",
      "Best threshold: -0.35077332206856704\n",
      "Left samples: 5852\n",
      "Right samples: 8469\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 4\n",
      "Samples: 2944\n",
      "Features: 10\n",
      "Best feature: 3\n",
      "Best threshold: 0.198227180438005\n",
      "Left samples: 1194\n",
      "Right samples: 1750\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 3\n",
      "Samples: 16686\n",
      "Features: 10\n",
      "Best feature: 8\n",
      "Best threshold: 1.4152615765527305\n",
      "Left samples: 15453\n",
      "Right samples: 1233\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 4\n",
      "Samples: 15453\n",
      "Features: 10\n",
      "Best feature: 4\n",
      "Best threshold: 0.2151660421625204\n",
      "Left samples: 9485\n",
      "Right samples: 5968\n",
      "==============================\n",
      "Calculating information gain for each feature...\n",
      "Feature 0\n",
      "Feature 1\n",
      "Feature 2\n",
      "Feature 3\n",
      "Feature 4\n",
      "Feature 5\n",
      "Feature 6\n",
      "Feature 7\n",
      "Feature 8\n",
      "Feature 9\n",
      "Depth: 4\n",
      "Samples: 1233\n",
      "Features: 10\n",
      "Best feature: 9\n",
      "Best threshold: 0.24923600875250207\n",
      "Left samples: 293\n",
      "Right samples: 940\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# create an instance of the DecisionTreeClassifier class\n",
    "D_tree = DecisionTreeClassifier()\n",
    "\n",
    "# fit the classifier on the training data\n",
    "D_tree.fit(X_res.values, y_res.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.DecisionTreeClassifier object at 0x7fe7dce64a58>\n"
     ]
    }
   ],
   "source": [
    "print(D_tree)\n",
    "\n",
    "y_pred = D_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     85295\n",
      "           1       0.01      0.41      0.03       148\n",
      "\n",
      "    accuracy                           0.95     85443\n",
      "   macro avg       0.51      0.68      0.50     85443\n",
      "weighted avg       1.00      0.95      0.97     85443\n",
      "\n",
      "AUC-ROC\n",
      "0.6779943376168243\n",
      "F1-Score\n",
      "0.027130906624463033\n",
      "Accuracy\n",
      "0.9496389405802699\n"
     ]
    }
   ],
   "source": [
    "print('CLASSIFICATION REPORT')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('AUC-ROC')\n",
    "print(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print('F1-Score')\n",
    "print(f1_score(y_test, y_pred))\n",
    "\n",
    "print('Accuracy')\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report and performance metrics obtained above suggest that the logistic regression model trained on credit card fraud detection data has poor performance in detecting fraudulent transactions (class 1).\n",
    "\n",
    "Precision: The precision for class 0 (non-fraudulent transactions) is high at 1.00, indicating that the model correctly predicted all instances of non-fraudulent transactions. However, the precision for class 1 (fraudulent transactions) is very low at 0.01. This means that the model identified a significant number of transactions as fraudulent that were actually non-fraudulent (false positives).\n",
    "\n",
    "Recall: The recall for class 0 is high at 0.95, indicating that the model correctly identified the majority of non-fraudulent transactions. However, the recall for class 1 is very low at 0.41. This means that the model missed a large number of actual fraudulent transactions (false negatives).\n",
    "\n",
    "F1-Score: The F1-score for class 0 is high at 0.97, indicating good performance in detecting non-fraudulent transactions. However, the F1-score for class 1 is very low at 0.03, indicating poor performance in detecting fraudulent transactions.\n",
    "\n",
    "Accuracy: The overall accuracy of the model is 0.95, which appears to be high. However, accuracy can be misleading in imbalanced datasets, such as credit card fraud detection, where the majority of transactions are non-fraudulent. In this case, the high accuracy is driven by the model's ability to correctly classify non-fraudulent transactions, while it performs poorly in detecting fraudulent transactions.\n",
    "\n",
    "Additionally, the AUC-ROC (Area Under the Receiver Operating Characteristic Curve) score is 0.6779, which suggests that the model's ability to distinguish between fraudulent and non-fraudulent transactions is close to random guessing.\n",
    "\n",
    "Overall, based on these results, the logistic regression model seems to have limited effectiveness in detecting credit card fraud. Further analysis, feature engineering, or the use of more sophisticated algorithms may be required to improve the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_pred, y_test):\n",
    "    class_names = np.unique(y_test)\n",
    "    table = []\n",
    "    for true_class in class_names:\n",
    "        row = []\n",
    "        for Y_class in class_names:\n",
    "            row.append(100 * np.mean(y_pred[y_test == true_class] == Y_class))\n",
    "        table.append(row)\n",
    "    conf_matrix = pd.DataFrame(table, index=class_names, columns=class_names)\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy in percent correct: 94.96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_0056b9c2_f057_11ed_b58f_c8d3ffbe8180row0_col0,#T_0056b9c2_f057_11ed_b58f_c8d3ffbe8180row1_col1{\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_0056b9c2_f057_11ed_b58f_c8d3ffbe8180row0_col1,#T_0056b9c2_f057_11ed_b58f_c8d3ffbe8180row1_col0{\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_0056b9c2_f057_11ed_b58f_c8d3ffbe8180\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>        <th class=\"col_heading level0 col1\" >1</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_0056b9c2_f057_11ed_b58f_c8d3ffbe8180level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_0056b9c2_f057_11ed_b58f_c8d3ffbe8180row0_col0\" class=\"data row0 col0\" >95.1 %</td>\n",
       "                        <td id=\"T_0056b9c2_f057_11ed_b58f_c8d3ffbe8180row0_col1\" class=\"data row0 col1\" >4.9 %</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0056b9c2_f057_11ed_b58f_c8d3ffbe8180level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_0056b9c2_f057_11ed_b58f_c8d3ffbe8180row1_col0\" class=\"data row1 col0\" >59.5 %</td>\n",
       "                        <td id=\"T_0056b9c2_f057_11ed_b58f_c8d3ffbe8180row1_col1\" class=\"data row1 col1\" >40.5 %</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe7dce64ba8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_correct = 100 * np.mean(y_pred == y_test)\n",
    "print(f'Test accuracy in percent correct: {perc_correct:.2f}')\n",
    "cm = confusion_matrix(y_pred, y_test)\n",
    "cm.style.background_gradient(cmap = 'Blues').format(\"{:.1f} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy is 94.96%, which means that the model correctly classified 94.96% of the transactions in the test set. The confusion matrix provides information about the model's performance for each class. The rows correspond to the true classes, and the columns correspond to the predicted classes. Looking at the confusion matrix, we can see that the model correctly identified 95.1% of non-fraudulent transactions (true negatives), but only 40.5% of fraudulent transactions (true positives). The model incorrectly predicted 4.9% of non-fraudulent transactions as fraudulent (false positives), and 59.5% of fraudulent transactions as non-fraudulent (false negatives).\n",
    "\n",
    "The high number of false negatives indicates that the model has a high rate of missing fraudulent transactions, which is a critical issue in credit card fraud detection. This suggests that the model may require further improvements, such as additional data preprocessing, feature engineering, or the use of more advanced algorithms to better detect fraudulent transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop(labels='Class', axis=1) # Features\n",
    "y = df1.loc[:,'Class']               # Target Variable\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Synthetic Minority Oversampling\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "mutual_infos = pd.Series(data=mutual_info_classif(X_res, y_res, discrete_features=False, random_state=1), index=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V14       0.535037\n",
       "V10       0.464777\n",
       "V12       0.456051\n",
       "V17       0.438193\n",
       "V4        0.427426\n",
       "V11       0.404044\n",
       "Amount    0.392941\n",
       "V3        0.387191\n",
       "V16       0.335318\n",
       "V7        0.304175\n",
       "V2        0.291492\n",
       "V9        0.256679\n",
       "Time      0.247989\n",
       "V21       0.235031\n",
       "V27       0.229915\n",
       "V1        0.220743\n",
       "V18       0.198264\n",
       "V8        0.174393\n",
       "V6        0.171974\n",
       "V28       0.170493\n",
       "V5        0.157362\n",
       "V20       0.107488\n",
       "V19       0.099837\n",
       "V23       0.067332\n",
       "V24       0.063567\n",
       "V26       0.046973\n",
       "V25       0.031607\n",
       "V22       0.031539\n",
       "V13       0.024931\n",
       "V15       0.022442\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_infos.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of Classifiers\n",
    "def grid_eval(grid_clf):\n",
    "    \"\"\"\n",
    "        Method to Compute the best score and parameters computed by grid search\n",
    "        Parameter:\n",
    "            grid_clf: The Grid Search Classifier \n",
    "    \"\"\"\n",
    "    print(\"Best Score\", grid_clf.best_score_)\n",
    "    print(\"Best Parameter\", grid_clf.best_params_)\n",
    "    \n",
    "def evaluation(y_test, grid_clf, X_test):\n",
    "    \"\"\"\n",
    "        Method to compute the following:\n",
    "            1. Classification Report\n",
    "            2. F1-score\n",
    "            3. AUC-ROC score\n",
    "            4. Accuracy\n",
    "        Parameters:\n",
    "            y_test: The target variable test set\n",
    "            grid_clf: Grid classifier selected\n",
    "            X_test: Input Feature Test Set\n",
    "    \"\"\"\n",
    "    y_pred = grid_clf.predict(X_test)\n",
    "    print('CLASSIFICATION REPORT')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print('AUC-ROC')\n",
    "    print(roc_auc_score(y_test, y_pred))\n",
    "      \n",
    "    print('F1-Score')\n",
    "    print(f1_score(y_test, y_pred))\n",
    "    \n",
    "    print('Accuracy')\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('model',\n",
       "                                        DecisionTreeClassifier(random_state=1))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__criterion': ['gini', 'entropy'],\n",
       "                         'model__max_depth': [5, 10, None],\n",
       "                         'model__min_samples_leaf': [1, 2, 4],\n",
       "                         'model__min_samples_split': [2, 5, 10]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_dt = Pipeline([\n",
    "('model', DT_SK(random_state=1))\n",
    "])\n",
    "# Define parameter grid\n",
    "param_grid_dt = {\n",
    "    'model__criterion': ['gini', 'entropy'],\n",
    "    'model__max_depth': [5, 10, None],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "# Perform grid search\n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=pipeline_dt, \n",
    "    param_grid=param_grid_dt, \n",
    "    scoring='accuracy', \n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score 0.9994331982726941\n",
      "Best Parameter {'model__criterion': 'gini', 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "grid_eval(grid_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85295\n",
      "           1       0.89      0.84      0.86       148\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.94      0.92      0.93     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "AUC-ROC\n",
      "0.918825126785734\n",
      "F1-Score\n",
      "0.8611111111111112\n",
      "Accuracy\n",
      "0.9995318516437859\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_test, grid_dt, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report and performance metrics obtained above suggest that the model trained on credit card fraud detection data has high performance in detecting fraudulent transactions (class 1).\n",
    "\n",
    "Precision: The precision for class 0 (non-fraudulent transactions) is 1.00, indicating that the model correctly predicted all instances of non-fraudulent transactions. The precision for class 1 (fraudulent transactions) is also high at 0.89, indicating that the model identified a large number of transactions as fraudulent that were actually fraudulent.\n",
    "\n",
    "Recall: The recall for class 0 is 1.00, indicating that the model correctly identified all instances of non-fraudulent transactions. The recall for class 1 is also good at 0.84. This means that the model correctly identified 84% of actual fraudulent transactions.\n",
    "\n",
    "F1-Score: The F1-score for class 0 is 1.00, indicating excellent performance in detecting non-fraudulent transactions. The F1-score for class 1 is also good at 0.86, indicating good performance in detecting fraudulent transactions.\n",
    "\n",
    "Accuracy: The overall accuracy of the model is 0.9995, which is very high. This suggests that the model is correctly classifying the majority of transactions.\n",
    "\n",
    "Additionally, the AUC-ROC (Area Under the Receiver Operating Characteristic Curve) score is 0.9188, which is also high. This suggests that the model's ability to distinguish between fraudulent and non-fraudulent transactions is good.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between the two classes is that the sklearn class achieved much higher scores in terms of precision, recall, and F1-score for class 1 (fraudulent transactions). Specifically, the sklearn class achieved a precision of 0.89, recall of 0.84, and F1-score of 0.86 for class 1, whereas the custom class achieved a precision of only 0.01, recall of 0.41, and F1-score of 0.03 for the same class.\n",
    "\n",
    "The AUC-ROC scores for both models were similar, with the custom class achieving a score of 0.919 and the custom class achieving a score of 0.678. The sklearn class achieved a slightly higher overall accuracy of 0.9995 compared to the custom class accuracy of 0.95.\n",
    "\n",
    "In conclusion, the sklearn class seems to have better performance than the custom class in detecting fraudulent transactions in the credit card fraud dataset. However, more analysis is needed to confirm this result and to identify which algorithm is best suited for this task. It is also important to note that further feature engineering or the use of more sophisticated algorithms may be necessary to further improve the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data - https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
